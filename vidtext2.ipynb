{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T22:03:04.854159Z","iopub.status.busy":"2024-04-12T22:03:04.853345Z","iopub.status.idle":"2024-04-12T22:03:16.947820Z","shell.execute_reply":"2024-04-12T22:03:16.946731Z","shell.execute_reply.started":"2024-04-12T22:03:04.854125Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (0.25.1)\n"]}],"source":["! pip install pydub"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T22:03:25.175182Z","iopub.status.busy":"2024-04-12T22:03:25.174778Z","iopub.status.idle":"2024-04-12T22:03:25.191283Z","shell.execute_reply":"2024-04-12T22:03:25.190461Z","shell.execute_reply.started":"2024-04-12T22:03:25.175137Z"},"trusted":true},"outputs":[],"source":["from pytube import YouTube\n","from pydub import AudioSegment\n","import librosa\n","from audio_extract import extract_audio\n","from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM, AutoProcessor, AutoModelForSpeechSeq2Seq"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T21:46:46.039162Z","iopub.status.busy":"2024-04-12T21:46:46.038575Z","iopub.status.idle":"2024-04-12T21:47:32.023886Z","shell.execute_reply":"2024-04-12T21:47:32.022676Z","shell.execute_reply.started":"2024-04-12T21:46:46.039134Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed626b5de79a42f894c336aac29fdfc0","version_major":2,"version_minor":0},"text/plain":["preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eef2ac4174954b3795c3667f949d0f51","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"771fcd1e14b64821b724297711bbfbf8","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7924d700e2f4c3198e48ae39d97967c","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dbe0c3a108814f309c3ba17c5f2be6ec","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a04a3cb7fd34083b1561e82101f98ff","version_major":2,"version_minor":0},"text/plain":["normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"584c8172b3024294a7fe40d76c26a8a8","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c5e1c0c5ad14b4992a97fb202beeac5","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4740e5672e241fb9f585ef5fc832e08","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"114b46f5a2c74b44a6826e8ebbbf7cbd","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c581b080fff3422ca270ae8ac5e2965f","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/3.90k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["audio_model_id = \"openai/whisper-large-v3\"\n","\n","processor = AutoProcessor.from_pretrained(\"openai/whisper-large-v3\")\n","audio_model = AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-large-v3\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T21:47:32.027509Z","iopub.status.busy":"2024-04-12T21:47:32.027096Z","iopub.status.idle":"2024-04-12T21:47:32.131798Z","shell.execute_reply":"2024-04-12T21:47:32.130448Z","shell.execute_reply.started":"2024-04-12T21:47:32.027469Z"},"trusted":true},"outputs":[],"source":["\n","# https://youtube.com/shorts/FJtFZwbvkI4?si=EmT9MhTuRvP26FzA\n","\n","url = \"https://youtube.com/shorts/FJtFZwbvkI4?si=EmT9MhTuRvP26FzA\"\n","\n","video = YouTube(url)\n","\n","title = video.title\n","\n","output_file = f'{title}.mp4'"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T21:47:32.133475Z","iopub.status.busy":"2024-04-12T21:47:32.133064Z","iopub.status.idle":"2024-04-12T21:47:35.164474Z","shell.execute_reply":"2024-04-12T21:47:35.163460Z","shell.execute_reply.started":"2024-04-12T21:47:32.133440Z"},"trusted":true},"outputs":[],"source":["video_dld = video.streams.filter(progressive=True, file_extension=\"mp4\").order_by(\"resolution\").desc().first().download()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T21:55:28.011671Z","iopub.status.busy":"2024-04-12T21:55:28.011289Z","iopub.status.idle":"2024-04-12T21:55:28.040190Z","shell.execute_reply":"2024-04-12T21:55:28.039266Z","shell.execute_reply.started":"2024-04-12T21:55:28.011644Z"},"trusted":true},"outputs":[],"source":["import torch\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T21:47:35.166817Z","iopub.status.busy":"2024-04-12T21:47:35.165925Z","iopub.status.idle":"2024-04-12T21:47:36.560436Z","shell.execute_reply":"2024-04-12T21:47:36.559438Z","shell.execute_reply.started":"2024-04-12T21:47:35.166779Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Success : audio file has been saved to \"/kaggle/working/How word vectors encode meaning1.mp3\".\n"]}],"source":["audio_file = extract_audio(input_path=video_dld, output_path=f'{title}1.mp3')"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T21:51:00.100453Z","iopub.status.busy":"2024-04-12T21:51:00.099798Z","iopub.status.idle":"2024-04-12T21:51:05.285432Z","shell.execute_reply":"2024-04-12T21:51:05.284642Z","shell.execute_reply.started":"2024-04-12T21:51:00.100421Z"},"trusted":true},"outputs":[],"source":["# audio_sample, s_rate = librosa.load('/kaggle/working/How word vectors encode meaning1.mp3', sr=None)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T22:04:44.874689Z","iopub.status.busy":"2024-04-12T22:04:44.874011Z","iopub.status.idle":"2024-04-12T22:04:45.232081Z","shell.execute_reply":"2024-04-12T22:04:45.231088Z","shell.execute_reply.started":"2024-04-12T22:04:44.874649Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<_io.BufferedRandom name='audio_file.wav'>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["mp3_file = \"/kaggle/working/How word vectors encode meaning1.mp3\"\n","audio = AudioSegment.from_file(mp3_file, format=\"mp3\")\n","\n","# Export the audio as a WAV file\n","wav_file = \"audio_file.wav\"\n","audio.export(wav_file, format=\"wav\")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T22:05:21.619070Z","iopub.status.busy":"2024-04-12T22:05:21.618731Z","iopub.status.idle":"2024-04-12T22:05:21.623351Z","shell.execute_reply":"2024-04-12T22:05:21.622328Z","shell.execute_reply.started":"2024-04-12T22:05:21.619047Z"},"trusted":true},"outputs":[],"source":["wav_file = '/kaggle/working/audio_file.wav'"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T21:55:41.588583Z","iopub.status.busy":"2024-04-12T21:55:41.587875Z","iopub.status.idle":"2024-04-12T21:55:50.808199Z","shell.execute_reply":"2024-04-12T21:55:50.807085Z","shell.execute_reply.started":"2024-04-12T21:55:41.588552Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b72749fa744848f3bed7a36ec84626af","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c23162e156434ea3b631b1e9367eba47","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n","- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb52ea63010a434aa836ffd49e76740c","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca11b5fd70154c5fa970f66d65ada29e","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ded05fb57fb4e87ae96a89a4bcd459c","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"948b8f81894f4df2a122b0070b4b41c2","version_major":2,"version_minor":0},"text/plain":["preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["transcriber = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\", chunk_length_s=30, device=device)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T22:07:23.263471Z","iopub.status.busy":"2024-04-12T22:07:23.262943Z","iopub.status.idle":"2024-04-12T22:07:23.711821Z","shell.execute_reply":"2024-04-12T22:07:23.710860Z","shell.execute_reply.started":"2024-04-12T22:07:23.263436Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'text': \"WHAT IS ITLER PLUS ITALY MINUS GERMANY THIS CAME UP IN A FOLVIDIO THAT I DID DISSECTING WHAT HAPPENS INSIDE LARGE LANGUAGE MODELS YOU SEE WHEN TOOLS LIKE CHATCHE P T PROCESS TEXT THE FIRST THING THEY DO IS SUBDIVIDED INTO LITTLE PIECES AND THE ASSOCIATE EACH PIECE WITH A LARGE VECTOR SOME LONG LIST OF NUMBERS THIS IS CALLED AN IMBETTING OF THAT PIECE OF TEXT AND IT'S HELPFUL TO IMAGINE THESE IMBETTING VECTORS AS DIRECTIONS IN SOME VERY HIGH DIMENSIONAL SPACE EVEN IF WE STRUGGLE TO CONCRETELY VISUALIZE ANYTHING MORE THAN THREE DIMENSIONS MODELS THAT LEARN TO IMBED WORDS AS VECTORS LIKE THIS OFTEN INCODE MEANING INTO THE DIRECTIONS OF THIS HIGH DIMENSIONAL SPACE IF YOU TAKE THE DIFFERENCE BETWEEN THE IMBETTINGS OF MAN AND WOMAN AND YOU ADD THAT TO THE IMBETTING OF UNCLE YOU GET A VECTOR VERY CLOSE TO THE IMBETTING OF AUNT IF YOU TAKE THE IMBETTING OF ITALY MINUS GERMANY AND YOU ADD IT TO THE IMBETTING OF HITLER YOU GET SOMETHING VERY CLOSE TO THE IMBETTING OF MUSELINI IT'S AS IF THE MODEL LEARNED TO ASSOCIATE SOME DIRECTIONS IN THIS HIGH DIMENTIONAL SPACE WITH ITALIANNESS AND OTHERS WITH WORLD WERE TWO AXESS LEADERS\"}\n"]}],"source":["text_extract = transcriber(wav_file)\n","print(text_extract)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T22:07:43.141689Z","iopub.status.busy":"2024-04-12T22:07:43.141309Z","iopub.status.idle":"2024-04-12T22:07:43.147941Z","shell.execute_reply":"2024-04-12T22:07:43.147041Z","shell.execute_reply.started":"2024-04-12T22:07:43.141659Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"what is itler plus italy minus germany this came up in a folvidio that i did dissecting what happens inside large language models you see when tools like chatche p t process text the first thing they do is subdivided into little pieces and the associate each piece with a large vector some long list of numbers this is called an imbetting of that piece of text and it's helpful to imagine these imbetting vectors as directions in some very high dimensional space even if we struggle to concretely visualize anything more than three dimensions models that learn to imbed words as vectors like this often incode meaning into the directions of this high dimensional space if you take the difference between the imbettings of man and woman and you add that to the imbetting of uncle you get a vector very close to the imbetting of aunt if you take the imbetting of italy minus germany and you add it to the imbetting of hitler you get something very close to the imbetting of muselini it's as if the model learned to associate some directions in this high dimentional space with italianness and others with world were two axess leaders\""]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["text_extract['text'].lower()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
